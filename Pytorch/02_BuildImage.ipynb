{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Docker image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will build the docker container that contains the ResNet152 model, Flask web application, model driver and all dependencies.\n",
    "Make sure you have logged in using docker login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import shutil\n",
    "from dotenv import set_key, get_key, find_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a .env file to store all our information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv()\n",
    "if env_path=='':\n",
    "    Path('.env').touch()\n",
    "    env_path = find_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the following Docker information to push the image to docker hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_key(env_path, \"docker_login\", \"YOUR_DOCKER_LOGIN\") # Replace YOUR_DOCKER_LOGIN with your dockerhub login\n",
    "set_key(env_path, \"image_repo\", \"pytorch-gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"flaskwebapp\", exist_ok=True)\n",
    "os.makedirs(os.path.join(\"flaskwebapp\", \"nginx\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(\"flaskwebapp\", \"etc\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(\"synset.txt\", \"flaskwebapp\")\n",
    "shutil.copy(\"driver.py\", \"flaskwebapp\")\n",
    "os.listdir(\"flaskwebapp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create the module for the Flask web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/app.py\n",
    "\n",
    "from flask import Flask, request, Response\n",
    "import logging\n",
    "import json\n",
    "import driver\n",
    "\n",
    "app = Flask(__name__)\n",
    "predict_for = driver.get_model_api()\n",
    " \n",
    "@app.route(\"/score\", methods = ['POST'])\n",
    "def scoreRRS():\n",
    "    \"\"\" Endpoint for scoring\n",
    "    \"\"\"\n",
    "    if request.headers['Content-Type'] != 'application/json':\n",
    "        return Response(json.dumps({}), status= 415, mimetype ='application/json')\n",
    "    request_input = request.json['input']\n",
    "    response = predict_for(request_input)\n",
    "    return json.dumps({'result': response})\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def healthy():\n",
    "    return \"Healthy\"\n",
    "\n",
    "# PyTorch Version\n",
    "@app.route('/version', methods = ['GET'])\n",
    "def version_request():\n",
    "    return driver.version()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/wsgi.py\n",
    "from app import app as application\n",
    "\n",
    "def create():\n",
    "    print(\"Initialising\")\n",
    "    application.run(host='127.0.0.1', port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we write the configuration for the Nginx which creates a proxy between ports **80** and **5000**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/nginx/app\n",
    "server {\n",
    "    listen 80;\n",
    "    server_name _;\n",
    " \n",
    "    location / {\n",
    "    include proxy_params;\n",
    "    proxy_pass http://127.0.0.1:5000;\n",
    "    proxy_connect_timeout 5000s;\n",
    "    proxy_read_timeout 5000s;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/gunicorn_logging.conf\n",
    "\n",
    "[loggers]\n",
    "keys=root, gunicorn.error\n",
    "\n",
    "[handlers]\n",
    "keys=console\n",
    "\n",
    "[formatters]\n",
    "keys=json\n",
    "\n",
    "[logger_root]\n",
    "level=INFO\n",
    "handlers=console\n",
    "\n",
    "[logger_gunicorn.error]\n",
    "level=ERROR\n",
    "handlers=console\n",
    "propagate=0\n",
    "qualname=gunicorn.error\n",
    "\n",
    "[handler_console]\n",
    "class=StreamHandler\n",
    "formatter=json\n",
    "args=(sys.stdout, )\n",
    "\n",
    "[formatter_json]\n",
    "class=jsonlogging.JSONFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/kill_supervisor.py\n",
    "import sys\n",
    "import os\n",
    "import signal\n",
    "\n",
    "def write_stdout(s):\n",
    "    sys.stdout.write(s)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# this function is modified from the code and knowledge found here: http://supervisord.org/events.html#example-event-listener-implementation\n",
    "def main():\n",
    "    while 1:\n",
    "        write_stdout('READY\\n')\n",
    "        # wait for the event on stdin that supervisord will send\n",
    "        line = sys.stdin.readline()\n",
    "        write_stdout('Killing supervisor with this event: ' + line);\n",
    "        try:\n",
    "            # supervisord writes its pid to its file from which we read it here, see supervisord.conf\n",
    "            pidfile = open('/tmp/supervisord.pid','r')\n",
    "            pid = int(pidfile.readline());\n",
    "            os.kill(pid, signal.SIGQUIT)\n",
    "        except Exception as e:\n",
    "            write_stdout('Could not kill supervisor: ' + e.strerror + '\\n')\n",
    "            write_stdout('RESULT 2\\nOK')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/etc/supervisord.conf \n",
    "[supervisord]\n",
    "logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)\n",
    "logfile_maxbytes=50MB        ; (max main logfile bytes b4 rotation;default 50MB)\n",
    "logfile_backups=10           ; (num of main logfile rotation backups;default 10)\n",
    "loglevel=info                ; (log level;default info; others: debug,warn,trace)\n",
    "pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)\n",
    "nodaemon=true                ; (start in foreground if true;default false)\n",
    "minfds=1024                  ; (min. avail startup file descriptors;default 1024)\n",
    "minprocs=200                 ; (min. avail process descriptors;default 200)\n",
    "\n",
    "[program:gunicorn]\n",
    "command=bash -c \"gunicorn --workers 1 -m 007 --timeout 100000 --capture-output --error-logfile - --log-level debug --log-config gunicorn_logging.conf \\\"wsgi:create()\\\"\"\n",
    "directory=/code\n",
    "redirect_stderr=true\n",
    "stdout_logfile =/dev/stdout\n",
    "stdout_logfile_maxbytes=0\n",
    "startretries=2\n",
    "startsecs=20\n",
    "\n",
    "[program:nginx]\n",
    "command=/usr/sbin/nginx -g \"daemon off;\"\n",
    "startretries=2\n",
    "startsecs=5\n",
    "priority=3\n",
    "\n",
    "[eventlistener:program_exit]\n",
    "command=python kill_supervisor.py\n",
    "directory=/code\n",
    "events=PROCESS_STATE_FATAL\n",
    "priority=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a custom image based on the CUDA 9 image from NVIDIA and install all the necessary dependencies. This is in order to try and keep the size of the image as small as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/requirements.txt\n",
    "Pillow==5.0.0\n",
    "click==6.7\n",
    "configparser==3.5.0\n",
    "Flask==0.12.2\n",
    "gunicorn==19.6.0\n",
    "json-logging-py==0.2\n",
    "MarkupSafe==1.0\n",
    "olefile==0.44\n",
    "requests==2.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flaskwebapp/dockerfile\n",
    "\n",
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
    "\n",
    "RUN mkdir /code\n",
    "WORKDIR /code\n",
    "ADD . /code/\n",
    "ADD etc /etc\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential \\\n",
    "        ca-certificates \\\n",
    "        cmake \\\n",
    "        curl \\\n",
    "        git \\\n",
    "        nginx \\\n",
    "        supervisor \\\n",
    "        wget && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "\n",
    "ENV PYTHON_VERSION=3.6\n",
    "RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  && \\\n",
    "    chmod +x ~/miniconda.sh && \\\n",
    "    ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION numpy scipy pandas scikit-learn && \\\n",
    "    /opt/conda/bin/conda clean -ya\n",
    "ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
    "ENV PYTHONPATH /code/:$PYTHONPATH\n",
    "\n",
    "    \n",
    "RUN rm /etc/nginx/sites-enabled/default && \\\n",
    "    cp /code/nginx/app /etc/nginx/sites-available/ && \\\n",
    "    ln -s /etc/nginx/sites-available/app /etc/nginx/sites-enabled/ && \\\n",
    "    /opt/conda/bin/conda install -c pytorch pytorch==0.4.1 && \\\n",
    "    pip install --upgrade pip && \\\n",
    "    pip install torchvision==0.2.1 && \\\n",
    "    pip install -r /code/requirements.txt && \\       \n",
    "    /opt/conda/bin/conda clean -yt\n",
    "\n",
    "EXPOSE 80\n",
    "CMD [\"supervisord\", \"-c\", \"/code/etc/supervisord.conf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image name below refers to our dockerhub account. If you wish to push the image to your account make sure you change the docker login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = get_key(env_path, 'docker_login') + '/' +get_key(env_path, 'image_repo')\n",
    "image_name = 'YOUR_DOCKER_LOGIN/pytorch-gpu'\n",
    "application_path = 'flaskwebapp'\n",
    "docker_file_location = path.join(application_path, 'dockerfile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll login to docker.  \n",
    "We can run this on the **host**:  \n",
    "```\n",
    "sudo docker login -u myuser\n",
    "sudo chmod -R 777 /home/andy/.docker/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build our docker image. The output of this cell is cleared from this notebook as it is quite long due to all the installations required to build the image. However, you should make sure you see 'Successfully built' and 'Successfully tagged' messages in the last line of the output when you run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_name)\n",
    "print(docker_file_location)\n",
    "print(application_path)\n",
    "!docker build -t $image_name -f $docker_file_location $application_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will push the image created to our dockerhub registry. Make sure you have already logged in to the appropriate dockerhub account using the docker login command. If you haven't loged in to the approrpiate dockerhub account you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push $image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Docker image name {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now [test our image locally](03_TestLocally.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext_format_version": "1.3",
  "jupytext_formats": "py:light",
  "kernelspec": {
   "display_name": "Python [conda env:AKSDeploymentPytorch]",
   "language": "python",
   "name": "conda-env-AKSDeploymentPytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
