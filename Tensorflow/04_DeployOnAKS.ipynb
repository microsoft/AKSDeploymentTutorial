{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deploy Web App on Azure Container Services (AKS)\n",
    "In this notebook, we will set up an Azure Container Service which will be managed by Kubernetes. We will then take the Docker image we created earlier that contains our app and deploy it to the AKS cluster. Then, we will check everything is working by sending an image to it and getting it scored.\n",
    "    \n",
    "The process is split into the following steps:\n",
    "* [Define our resource names](#section1)\n",
    "* [Login to Azure](#section2)\n",
    "* [Create resource group and create AKS](#section3)\n",
    "* [Connect to AKS](#section4)\n",
    "* [Deploy our app](#section5)\n",
    "* [Tear it all down](#section6)\n",
    "\n",
    "This guide assumes is designed to be run on linux and requires that the Azure CLI is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Setup\n",
    "Below are the various name definitions for the resources needed to setup ACS as well as the name of the Docker image we will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some outputs (and inputs) below have been hidden/masked for confidentiality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please modify the below as you see fit\n",
    "resource_group = \"<RESOURCE_GROUP>\" \n",
    "aks_name = \"<AKS_CLUSTER_NAME>\"\n",
    "location = \"eastus\"\n",
    "\n",
    "image_name = '<YOUR_DOCKER_IMAGE>' # 'masalvar/tfresnet-gpu' Feel free to use this Image if you want to \n",
    "                                   # skip creating your own container\n",
    "selected_subscription = \"'<YOUR SUBSCRIPTION>'\" # If you have multiple subscriptions select \n",
    "                                                # the subscription you want to use here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Azure account login\n",
    "The command below will initiate a login to your Azure account. It will pop up with an url to go to where you will enter a one off code and log into your Azure account using your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az account set --subscription $selected_subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az account show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mRegistering is still on-going. You can monitor using 'az provider show -n Microsoft.ContainerService'\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!az provider register -n Microsoft.ContainerService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## Create resource group and create AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create resource group\n",
    "Azure encourages the use of groups to organise all the Azure components you deploy. That way it is easier to find them but also we can deleted a number of resources simply by deleting the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/msaksrg\",\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"msaksrg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az group create --name $resource_group --location $location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create the AKS cluster in the resource group we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"additionalProperties\": {},\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"additionalProperties\": {},\n",
      "      \"count\": 1,\n",
      "      \"dnsPrefix\": null,\n",
      "      \"fqdn\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"osDiskSizeGb\": null,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"ports\": null,\n",
      "      \"storageProfile\": \"ManagedDisks\",\n",
      "      \"vmSize\": \"Standard_NC6\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"dnsPrefix\": \"msAKSTFClu-msaksrg-edf507\",\n",
      "  \"fqdn\": \"msakstfclu-msaksrg-edf507-9dc6365c.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/msaksrg/providers/Microsoft.ContainerService/managedClusters/msAKSTFCluster\",\n",
      "  \"kubernetesVersion\": \"1.8.10\",\n",
      "  \"linuxProfile\": {\n",
      "    \"additionalProperties\": {},\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"additionalProperties\": {},\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"additionalProperties\": {},\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDVfKBWPBKS84wluD3DJ0t3hepO2F13pz1VI5d4c7Tn4d80rSKJkF2L2HtAf3w9R7TM5TYcSlMqv+OFtB5iwfMk1k8sarGqmB1aLuEYBD60cqtdWD34DPWz8Y4eQ7x8eQ2joVRgMFpv+SfEuPBaQdTM7QtFiWRA1ZioXElyniL2Snhsd/ICcq5SIcZSPj3z9/eUcKGz/eImLkOYU28l8fLpVg48x70rGOtpfmDmZJ3KT/LImDWbPFF4VIRuiki4qVaMvDvwlEB7BmqM5D8qO7tOM3ncZ3TqUhrSQj9NbeC65xvB83+BiZts63VXAsMLnu+0wbAXnA4W66ly/5UyjC//\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"msAKSTFCluster\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"msaksrg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"additionalProperties\": {},\n",
      "    \"clientId\": \"44ba57c3-4386-4788-a761-8d72faa493e2\",\n",
      "    \"keyVaultSecretRef\": null,\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks create --resource-group $resource_group --name $aks_name --node-count 1 --generate-ssh-keys -s Standard_NC6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install kubectl CLI\n",
    "\n",
    "To connect to the Kubernetes cluster, we will use kubectl, the Kubernetes command-line client. To install, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading client to /usr/local/bin/kubectl from https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl\u001b[0m\n",
      "\u001b[33mPlease ensure that /usr/local/bin is in your search PATH, so the `kubectl` command can be found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo az aks install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## Connect to AKS cluster\n",
    "\n",
    "To configure kubectl to connect to the Kubernetes cluster, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged \"msAKSTFCluster\" as current context in /home/mat/.kube/config\r\n"
     ]
    }
   ],
   "source": [
    "!az aks get-credentials --resource-group $resource_group --name $aks_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify connection by listing the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS    ROLES     AGE       VERSION\r\n",
      "aks-nodepool1-27496346-0   Ready     agent     3m        v1.8.10\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the pods on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "kube-system   heapster-75f8df9884-vlt25               2/2       Running   0          1m\r\n",
      "kube-system   kube-dns-v20-5bf84586f4-9jd9r           3/3       Running   0          1m\r\n",
      "kube-system   kube-dns-v20-5bf84586f4-f8nsn           3/3       Running   0          1m\r\n",
      "kube-system   kube-proxy-x64jp                        1/1       Running   0          1m\r\n",
      "kube-system   kube-svc-redirect-mkwss                 1/1       Running   0          1m\r\n",
      "kube-system   kubernetes-dashboard-665f768455-npsfh   1/1       Running   0          1m\r\n",
      "kube-system   tunnelfront-5c48644fb8-4c6dt            1/1       Running   0          1m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## Deploy application\n",
    "\n",
    "Below we define our Kubernetes manifest file for our service and load balancer. Note that we have to specify the volume mounts to the drivers that are located on the node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_template = {\n",
    "  \"apiVersion\": \"apps/v1beta1\",\n",
    "  \"kind\": \"Deployment\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"replicas\":1,\n",
    "      \"template\":{\n",
    "          \"metadata\":{\n",
    "              \"labels\":{\n",
    "                  \"app\":\"azure-dl\"\n",
    "              }\n",
    "          },\n",
    "          \"spec\":{\n",
    "              \"containers\":[\n",
    "                  {\n",
    "                      \"name\": \"azure-dl\",\n",
    "                      \"image\": image_name,\n",
    "                      \"env\":[\n",
    "                          {\n",
    "                              \"name\": \"LD_LIBRARY_PATH\",\n",
    "                              \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"ports\":[\n",
    "                          {\n",
    "                              \"containerPort\":80,\n",
    "                              \"name\":\"model\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"volumeMounts\":[\n",
    "                          {\n",
    "                            \"mountPath\": \"/usr/local/nvidia\",\n",
    "                            \"name\": \"nvidia\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"resources\":{\n",
    "                           \"requests\":{\n",
    "                               \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                           },\n",
    "                           \"limits\":{\n",
    "                               \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                           }\n",
    "                       }  \n",
    "                  }\n",
    "              ],\n",
    "              \"volumes\":[\n",
    "                  {\n",
    "                      \"name\": \"nvidia\",\n",
    "                      \"hostPath\":{\n",
    "                          \"path\":\"/usr/local/nvidia\"\n",
    "                      },\n",
    "                  },\n",
    "              ]\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "service_temp = {\n",
    "  \"apiVersion\": \"v1\",\n",
    "  \"kind\": \"Service\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"type\": \"LoadBalancer\",\n",
    "      \"ports\":[\n",
    "          {\n",
    "              \"port\":80\n",
    "          }\n",
    "      ],\n",
    "      \"selector\":{\n",
    "            \"app\":\"azure-dl\"\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_json_to_file(json_dict, filename, mode='w'):\n",
    "    with open(filename, mode) as outfile:\n",
    "        json.dump(json_dict, outfile, indent=4,sort_keys=True)\n",
    "        outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_json_to_file(app_template, 'az-dl.json') # We write the service template to the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_json_to_file(service_temp, 'az-dl.json', mode='a') # We add the loadbelanacer template to the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the manifest created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"apiVersion\": \"apps/v1beta1\",\r\n",
      "    \"kind\": \"Deployment\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"replicas\": 1,\r\n",
      "        \"template\": {\r\n",
      "            \"metadata\": {\r\n",
      "                \"labels\": {\r\n",
      "                    \"app\": \"azure-dl\"\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"spec\": {\r\n",
      "                \"containers\": [\r\n",
      "                    {\r\n",
      "                        \"env\": [\r\n",
      "                            {\r\n",
      "                                \"name\": \"LD_LIBRARY_PATH\",\r\n",
      "                                \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"image\": \"masalvar/tfresnet-gpu\",\r\n",
      "                        \"name\": \"azure-dl\",\r\n",
      "                        \"ports\": [\r\n",
      "                            {\r\n",
      "                                \"containerPort\": 80,\r\n",
      "                                \"name\": \"model\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"resources\": {\r\n",
      "                            \"limits\": {\r\n",
      "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\r\n",
      "                            },\r\n",
      "                            \"requests\": {\r\n",
      "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\r\n",
      "                            }\r\n",
      "                        },\r\n",
      "                        \"volumeMounts\": [\r\n",
      "                            {\r\n",
      "                                \"mountPath\": \"/usr/local/nvidia\",\r\n",
      "                                \"name\": \"nvidia\"\r\n",
      "                            }\r\n",
      "                        ]\r\n",
      "                    }\r\n",
      "                ],\r\n",
      "                \"volumes\": [\r\n",
      "                    {\r\n",
      "                        \"hostPath\": {\r\n",
      "                            \"path\": \"/usr/local/nvidia\"\r\n",
      "                        },\r\n",
      "                        \"name\": \"nvidia\"\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        }\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n",
      "{\r\n",
      "    \"apiVersion\": \"v1\",\r\n",
      "    \"kind\": \"Service\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"ports\": [\r\n",
      "            {\r\n",
      "                \"port\": 80\r\n",
      "            }\r\n",
      "        ],\r\n",
      "        \"selector\": {\r\n",
      "            \"app\": \"azure-dl\"\r\n",
      "        },\r\n",
      "        \"type\": \"LoadBalancer\"\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use kubectl create command to deploy our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" created\n",
      "service \"azure-dl\" created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the pod is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS             RESTARTS   AGE\r\n",
      "default       azure-dl-9db45b4f7-bqq5g                0/1       ImagePullBackOff   0          2m\r\n",
      "kube-system   heapster-75f8df9884-vlt25               2/2       Running            0          4m\r\n",
      "kube-system   kube-dns-v20-5bf84586f4-9jd9r           3/3       Running            0          5m\r\n",
      "kube-system   kube-dns-v20-5bf84586f4-f8nsn           3/3       Running            0          5m\r\n",
      "kube-system   kube-proxy-x64jp                        1/1       Running            0          5m\r\n",
      "kube-system   kube-svc-redirect-mkwss                 1/1       Running            0          5m\r\n",
      "kube-system   kubernetes-dashboard-665f768455-npsfh   1/1       Running            0          5m\r\n",
      "kube-system   tunnelfront-5c48644fb8-4c6dt            1/1       Running            0          5m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything goes wrong you can use the commands below to observe the events on the node as well as review the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST SEEN   FIRST SEEN   COUNT     NAME                                        KIND         SUBOBJECT                   TYPE      REASON                    SOURCE                                 MESSAGE\r\n",
      "13m         13m          1         aks-nodepool1-27496346-0.152457f2d4c9a0c1   Node                                     Normal    Starting                  kubelet, aks-nodepool1-27496346-0      Starting kubelet.\r\n",
      "11m         13m          8         aks-nodepool1-27496346-0.152457f2d68e13e7   Node                                     Normal    NodeHasSufficientDisk     kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeHasSufficientDisk\r\n",
      "11m         13m          8         aks-nodepool1-27496346-0.152457f2d68e3bbf   Node                                     Normal    NodeHasSufficientMemory   kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeHasSufficientMemory\r\n",
      "12m         13m          7         aks-nodepool1-27496346-0.152457f2d68ed1bf   Node                                     Normal    NodeHasNoDiskPressure     kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeHasNoDiskPressure\r\n",
      "13m         13m          1         aks-nodepool1-27496346-0.152457f2d6a0f2ce   Node                                     Normal    NodeAllocatableEnforced   kubelet, aks-nodepool1-27496346-0      Updated Node Allocatable limit across pods\r\n",
      "9m          9m           1         aks-nodepool1-27496346-0.152458224f43e592   Node                                     Normal    RegisteredNode            controllermanager                      Node aks-nodepool1-27496346-0 event: Registered Node aks-nodepool1-27496346-0 in Controller\r\n",
      "9m          9m           1         aks-nodepool1-27496346-0.15245824056578a2   Node                                     Normal    Starting                  kube-proxy, aks-nodepool1-27496346-0   Starting kube-proxy.\r\n",
      "6m          6m           1         azure-dl-9db45b4f7-bqq5g.152458484af7e9af   Pod                                      Normal    Scheduled                 default-scheduler                      Successfully assigned azure-dl-9db45b4f7-bqq5g to aks-nodepool1-27496346-0\r\n",
      "6m          6m           1         azure-dl-9db45b4f7-bqq5g.1524584856327c4a   Pod                                      Normal    SuccessfulMountVolume     kubelet, aks-nodepool1-27496346-0      MountVolume.SetUp succeeded for volume \"nvidia\" \r\n",
      "6m          6m           1         azure-dl-9db45b4f7-bqq5g.1524584857145997   Pod                                      Normal    SuccessfulMountVolume     kubelet, aks-nodepool1-27496346-0      MountVolume.SetUp succeeded for volume \"default-token-bb2wg\" \r\n",
      "4m          6m           2         azure-dl-9db45b4f7-bqq5g.1524584884dda263   Pod          spec.containers{azure-dl}   Normal    Pulling                   kubelet, aks-nodepool1-27496346-0      pulling image \"masalvar/tfresnet-gpu\"\r\n",
      "5m          5m           1         azure-dl-9db45b4f7-bqq5g.152458607ea65616   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-27496346-0      Failed to pull image \"masalvar/tfresnet-gpu\": rpc error: code = Canceled desc = context canceled\r\n",
      "5m          5m           2         azure-dl-9db45b4f7-bqq5g.152458607ea7d5af   Pod                                      Warning   FailedSync                kubelet, aks-nodepool1-27496346-0      Error syncing pod\r\n",
      "5m          5m           1         azure-dl-9db45b4f7-bqq5g.15245860c6aafe6f   Pod          spec.containers{azure-dl}   Normal    BackOff                   kubelet, aks-nodepool1-27496346-0      Back-off pulling image \"masalvar/tfresnet-gpu\"\r\n",
      "1m          1m           1         azure-dl-9db45b4f7-bqq5g.152458908b326961   Pod          spec.containers{azure-dl}   Normal    Pulled                    kubelet, aks-nodepool1-27496346-0      Successfully pulled image \"masalvar/tfresnet-gpu\"\r\n",
      "1m          1m           1         azure-dl-9db45b4f7-bqq5g.152458909644c422   Pod          spec.containers{azure-dl}   Normal    Created                   kubelet, aks-nodepool1-27496346-0      Created container\r\n",
      "1m          1m           1         azure-dl-9db45b4f7-bqq5g.152458909ed20818   Pod          spec.containers{azure-dl}   Normal    Started                   kubelet, aks-nodepool1-27496346-0      Started container\r\n",
      "6m          6m           1         azure-dl-9db45b4f7.152458484a8f532a         ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller                  Created pod: azure-dl-9db45b4f7-bqq5g\r\n",
      "6m          6m           1         azure-dl.1524584848faa7c7                   Deployment                               Normal    ScalingReplicaSet         deployment-controller                  Scaled up replica set azure-dl-9db45b4f7 to 1\r\n",
      "6m          6m           1         azure-dl.152458484c36803c                   Service                                  Normal    EnsuringLoadBalancer      service-controller                     Ensuring load balancer\r\n",
      "3m          3m           1         azure-dl.152458762827d674                   Service                                  Normal    EnsuredLoadBalancer       service-controller                     Ensured load balancer\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-11 09:45:52,173 CRIT Supervisor running as root (no user in config file)\r\n",
      "2018-04-11 09:45:52,175 INFO supervisord started with pid 1\r\n",
      "2018-04-11 09:45:53,178 INFO spawned: 'program_exit' with pid 9\r\n",
      "2018-04-11 09:45:53,179 INFO spawned: 'nginx' with pid 10\r\n",
      "2018-04-11 09:45:53,180 INFO spawned: 'gunicorn' with pid 11\r\n",
      "2018-04-11 09:45:54,211 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\r\n",
      "2018-04-11 09:45:54.734234: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n",
      "2018-04-11 09:45:58,739 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\r\n",
      "2018-04-11 09:46:01.556833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \r\n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\n",
      "pciBusID: 1705:00:00.0\r\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\r\n",
      "2018-04-11 09:46:01.556879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 1705:00:00.0, compute capability: 3.7)\r\n",
      "INFO:tensorflow:Restoring parameters from resnet_v1_152.ckpt\r\n",
      "{\"level\": \"INFO\", \"host\": \"azure-dl-9db45b4f7-bqq5g\", \"timestamp\": \"2018-04-11T09:46:07.076248Z\", \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/tensorflow/python/platform/tf_logging.py\", \"msg\": \"Restoring parameters from %s\", \"logger\": \"tensorflow\", \"message\": \"Restoring parameters from resnet_v1_152.ckpt\", \"stack_info\": null, \"tags\": []}\r\n",
      "{\"level\": \"INFO\", \"host\": \"azure-dl-9db45b4f7-bqq5g\", \"timestamp\": \"2018-04-11T09:46:08.969746Z\", \"path\": \"/code/driver.py\", \"logger\": \"model_driver\", \"message\": \"Model loading time: 14236.73 ms\", \"stack_info\": null, \"tags\": []}\r\n",
      "Initialising\r\n",
      "{\"level\": \"INFO\", \"host\": \"azure-dl-9db45b4f7-bqq5g\", \"timestamp\": \"2018-04-11T09:46:08.974735Z\", \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/werkzeug/_internal.py\", \"msg\": \" * Running on %s://%s:%d/ %s\", \"logger\": \"werkzeug\", \"message\": \" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\", \"stack_info\": null, \"tags\": []}\r\n",
      "2018-04-11 09:46:13,980 INFO success: gunicorn entered RUNNING state, process has stayed up for > than 20 seconds (startsecs)\r\n"
     ]
    }
   ],
   "source": [
    "pod_json = !kubectl get pods -o json\n",
    "pod_dict = json.loads(''.join(pod_json))\n",
    "!kubectl logs {pod_dict['items'][0]['metadata']['name']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take a few minutes for the service to populate the EXTERNAL-IP field. This will be the IP you use to call the service. You can also specify an IP to use please see the AKS documentation for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE\r\n",
      "azure-dl   LoadBalancer   10.0.63.93   13.82.95.158   80:31941/TCP   7m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service azure-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our deployed service we can move onto [testing it](05_TestWebApp.ipynb)  \n",
    "Below are the instructions to tear everything down once we are done with the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## Tear it all down \n",
    "Once you are done with your cluster you can use the following two commands to destroy it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" deleted\n",
      "service \"azure-dl\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f az-dl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az aks delete -n $aks_name -g $resource_group -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az group delete --name $resource_group -y"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
